{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2cf941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b334c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3954e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "756465d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv('C:\\\\ny_engineered.csv')\n",
    "df = pd.DataFrame(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b31078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c61431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting DateTime index\n",
    "df['date'] = pd.to_datetime(df.date)\n",
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44c30f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 39455 entries, 2015-07-02 00:00:00 to 2019-12-31 22:00:00\n",
      "Data columns (total 45 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   load         39455 non-null  float64\n",
      " 1   temp         39455 non-null  float64\n",
      " 2   humid        39455 non-null  float64\n",
      " 3   target       39455 non-null  float64\n",
      " 4   cwkend       39455 non-null  float64\n",
      " 5   mth_sin      39455 non-null  float64\n",
      " 6   mth_cos      39455 non-null  float64\n",
      " 7   hour_sin     39455 non-null  float64\n",
      " 8   hour_cos     39455 non-null  float64\n",
      " 9   hour_num     39455 non-null  float64\n",
      " 10  mth_num      39455 non-null  float64\n",
      " 11  cmonth_2.0   39455 non-null  int64  \n",
      " 12  cmonth_3.0   39455 non-null  int64  \n",
      " 13  cmonth_4.0   39455 non-null  int64  \n",
      " 14  cmonth_5.0   39455 non-null  int64  \n",
      " 15  cmonth_6.0   39455 non-null  int64  \n",
      " 16  cmonth_7.0   39455 non-null  int64  \n",
      " 17  cmonth_8.0   39455 non-null  int64  \n",
      " 18  cmonth_9.0   39455 non-null  int64  \n",
      " 19  cmonth_10.0  39455 non-null  int64  \n",
      " 20  cmonth_11.0  39455 non-null  int64  \n",
      " 21  cmonth_12.0  39455 non-null  int64  \n",
      " 22  chour_1.0    39455 non-null  int64  \n",
      " 23  chour_2.0    39455 non-null  int64  \n",
      " 24  chour_3.0    39455 non-null  int64  \n",
      " 25  chour_4.0    39455 non-null  int64  \n",
      " 26  chour_5.0    39455 non-null  int64  \n",
      " 27  chour_6.0    39455 non-null  int64  \n",
      " 28  chour_7.0    39455 non-null  int64  \n",
      " 29  chour_8.0    39455 non-null  int64  \n",
      " 30  chour_9.0    39455 non-null  int64  \n",
      " 31  chour_10.0   39455 non-null  int64  \n",
      " 32  chour_11.0   39455 non-null  int64  \n",
      " 33  chour_12.0   39455 non-null  int64  \n",
      " 34  chour_13.0   39455 non-null  int64  \n",
      " 35  chour_14.0   39455 non-null  int64  \n",
      " 36  chour_15.0   39455 non-null  int64  \n",
      " 37  chour_16.0   39455 non-null  int64  \n",
      " 38  chour_17.0   39455 non-null  int64  \n",
      " 39  chour_18.0   39455 non-null  int64  \n",
      " 40  chour_19.0   39455 non-null  int64  \n",
      " 41  chour_20.0   39455 non-null  int64  \n",
      " 42  chour_21.0   39455 non-null  int64  \n",
      " 43  chour_22.0   39455 non-null  int64  \n",
      " 44  chour_23.0   39455 non-null  int64  \n",
      "dtypes: float64(11), int64(34)\n",
      "memory usage: 13.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e78e1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the integer variables to int32 type to reduce memory usage\n",
    "df[['load', 'humid', 'target', 'hour_num', 'mth_num']] = \\\n",
    "    df[['load', 'humid', 'target', 'hour_num', 'mth_num']].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cfc8228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dummy variables to uint8 type to reduce memory usage\n",
    "df[['cmonth_2.0', 'cmonth_3.0', 'cmonth_4.0', 'cmonth_5.0', 'cmonth_6.0', 'cmonth_7.0', 'cmonth_8.0', 'cmonth_9.0',\n",
    "    'cmonth_10.0', 'cmonth_11.0', 'cmonth_12.0', 'chour_1.0', 'chour_2.0', 'chour_3.0', 'chour_4.0', 'chour_5.0',\n",
    "    'chour_6.0', 'chour_7.0', 'chour_8.0', 'chour_9.0', 'chour_10.0', 'chour_11.0', 'chour_12.0', 'chour_13.0', \n",
    "    'chour_14.0', 'chour_15.0', 'chour_16.0', 'chour_17.0', 'chour_18.0', 'chour_19.0', 'chour_20.0', 'chour_21.0',\n",
    "    'chour_22.0', 'chour_23.0', 'cwkend']] = \\\n",
    "    df[['cmonth_2.0', 'cmonth_3.0', 'cmonth_4.0', 'cmonth_5.0', 'cmonth_6.0', 'cmonth_7.0', 'cmonth_8.0', \n",
    "        'cmonth_9.0', 'cmonth_10.0', 'cmonth_11.0', 'cmonth_12.0', 'chour_1.0', 'chour_2.0', 'chour_3.0',\n",
    "        'chour_4.0', 'chour_5.0', 'chour_6.0', 'chour_7.0', 'chour_8.0', 'chour_9.0', 'chour_10.0', 'chour_11.0',\n",
    "        'chour_12.0', 'chour_13.0', 'chour_14.0', 'chour_15.0', 'chour_16.0', 'chour_17.0', 'chour_18.0',\n",
    "        'chour_19.0', 'chour_20.0', 'chour_21.0', 'chour_22.0', 'chour_23.0', 'cwkend']].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d93f026c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 39455 entries, 2015-07-02 00:00:00 to 2019-12-31 22:00:00\n",
      "Data columns (total 45 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   load         39455 non-null  int32  \n",
      " 1   temp         39455 non-null  float64\n",
      " 2   humid        39455 non-null  int32  \n",
      " 3   target       39455 non-null  int32  \n",
      " 4   cwkend       39455 non-null  uint8  \n",
      " 5   mth_sin      39455 non-null  float64\n",
      " 6   mth_cos      39455 non-null  float64\n",
      " 7   hour_sin     39455 non-null  float64\n",
      " 8   hour_cos     39455 non-null  float64\n",
      " 9   hour_num     39455 non-null  int32  \n",
      " 10  mth_num      39455 non-null  int32  \n",
      " 11  cmonth_2.0   39455 non-null  uint8  \n",
      " 12  cmonth_3.0   39455 non-null  uint8  \n",
      " 13  cmonth_4.0   39455 non-null  uint8  \n",
      " 14  cmonth_5.0   39455 non-null  uint8  \n",
      " 15  cmonth_6.0   39455 non-null  uint8  \n",
      " 16  cmonth_7.0   39455 non-null  uint8  \n",
      " 17  cmonth_8.0   39455 non-null  uint8  \n",
      " 18  cmonth_9.0   39455 non-null  uint8  \n",
      " 19  cmonth_10.0  39455 non-null  uint8  \n",
      " 20  cmonth_11.0  39455 non-null  uint8  \n",
      " 21  cmonth_12.0  39455 non-null  uint8  \n",
      " 22  chour_1.0    39455 non-null  uint8  \n",
      " 23  chour_2.0    39455 non-null  uint8  \n",
      " 24  chour_3.0    39455 non-null  uint8  \n",
      " 25  chour_4.0    39455 non-null  uint8  \n",
      " 26  chour_5.0    39455 non-null  uint8  \n",
      " 27  chour_6.0    39455 non-null  uint8  \n",
      " 28  chour_7.0    39455 non-null  uint8  \n",
      " 29  chour_8.0    39455 non-null  uint8  \n",
      " 30  chour_9.0    39455 non-null  uint8  \n",
      " 31  chour_10.0   39455 non-null  uint8  \n",
      " 32  chour_11.0   39455 non-null  uint8  \n",
      " 33  chour_12.0   39455 non-null  uint8  \n",
      " 34  chour_13.0   39455 non-null  uint8  \n",
      " 35  chour_14.0   39455 non-null  uint8  \n",
      " 36  chour_15.0   39455 non-null  uint8  \n",
      " 37  chour_16.0   39455 non-null  uint8  \n",
      " 38  chour_17.0   39455 non-null  uint8  \n",
      " 39  chour_18.0   39455 non-null  uint8  \n",
      " 40  chour_19.0   39455 non-null  uint8  \n",
      " 41  chour_20.0   39455 non-null  uint8  \n",
      " 42  chour_21.0   39455 non-null  uint8  \n",
      " 43  chour_22.0   39455 non-null  uint8  \n",
      " 44  chour_23.0   39455 non-null  uint8  \n",
      "dtypes: float64(5), int32(5), uint8(35)\n",
      "memory usage: 3.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd528f",
   "metadata": {},
   "source": [
    "# Create Dummies & Numeric Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d4608d",
   "metadata": {},
   "source": [
    "Form **two** separate datasets:\n",
    "- DataFrame with **dummy month and hour variables**\n",
    "- DataFrame with **single numerical month and hour variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6fec7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dummy seasonality dataset\n",
    "df_dum = df.drop(['mth_sin', 'mth_cos', 'hour_sin', 'hour_cos', 'mth_num', 'hour_num'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b053b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The numeric seasonality dataset\n",
    "df_num = df[['load', 'temp', 'humid', 'target', 'cwkend', 'mth_num', 'hour_num']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c6e50",
   "metadata": {},
   "source": [
    "# Preparing Data for Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2087498b",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "696d6fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set test set at 20% of data\n",
    "sample = int(len(df)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9866ee92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7891"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdc0d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dummy seasonality dataset\n",
    "df_dumt = df_dum.iloc[-sample:]\n",
    "df_dum = df_dum.iloc[:-sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6725bece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 31564 entries, 2015-07-02 00:00:00 to 2019-02-06 03:00:00\n",
      "Data columns (total 39 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   load         31564 non-null  int32  \n",
      " 1   temp         31564 non-null  float64\n",
      " 2   humid        31564 non-null  int32  \n",
      " 3   target       31564 non-null  int32  \n",
      " 4   cwkend       31564 non-null  uint8  \n",
      " 5   cmonth_2.0   31564 non-null  uint8  \n",
      " 6   cmonth_3.0   31564 non-null  uint8  \n",
      " 7   cmonth_4.0   31564 non-null  uint8  \n",
      " 8   cmonth_5.0   31564 non-null  uint8  \n",
      " 9   cmonth_6.0   31564 non-null  uint8  \n",
      " 10  cmonth_7.0   31564 non-null  uint8  \n",
      " 11  cmonth_8.0   31564 non-null  uint8  \n",
      " 12  cmonth_9.0   31564 non-null  uint8  \n",
      " 13  cmonth_10.0  31564 non-null  uint8  \n",
      " 14  cmonth_11.0  31564 non-null  uint8  \n",
      " 15  cmonth_12.0  31564 non-null  uint8  \n",
      " 16  chour_1.0    31564 non-null  uint8  \n",
      " 17  chour_2.0    31564 non-null  uint8  \n",
      " 18  chour_3.0    31564 non-null  uint8  \n",
      " 19  chour_4.0    31564 non-null  uint8  \n",
      " 20  chour_5.0    31564 non-null  uint8  \n",
      " 21  chour_6.0    31564 non-null  uint8  \n",
      " 22  chour_7.0    31564 non-null  uint8  \n",
      " 23  chour_8.0    31564 non-null  uint8  \n",
      " 24  chour_9.0    31564 non-null  uint8  \n",
      " 25  chour_10.0   31564 non-null  uint8  \n",
      " 26  chour_11.0   31564 non-null  uint8  \n",
      " 27  chour_12.0   31564 non-null  uint8  \n",
      " 28  chour_13.0   31564 non-null  uint8  \n",
      " 29  chour_14.0   31564 non-null  uint8  \n",
      " 30  chour_15.0   31564 non-null  uint8  \n",
      " 31  chour_16.0   31564 non-null  uint8  \n",
      " 32  chour_17.0   31564 non-null  uint8  \n",
      " 33  chour_18.0   31564 non-null  uint8  \n",
      " 34  chour_19.0   31564 non-null  uint8  \n",
      " 35  chour_20.0   31564 non-null  uint8  \n",
      " 36  chour_21.0   31564 non-null  uint8  \n",
      " 37  chour_22.0   31564 non-null  uint8  \n",
      " 38  chour_23.0   31564 non-null  uint8  \n",
      "dtypes: float64(1), int32(3), uint8(35)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "df_dum.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d70c41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 7891 entries, 2019-02-06 04:00:00 to 2019-12-31 22:00:00\n",
      "Data columns (total 39 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   load         7891 non-null   int32  \n",
      " 1   temp         7891 non-null   float64\n",
      " 2   humid        7891 non-null   int32  \n",
      " 3   target       7891 non-null   int32  \n",
      " 4   cwkend       7891 non-null   uint8  \n",
      " 5   cmonth_2.0   7891 non-null   uint8  \n",
      " 6   cmonth_3.0   7891 non-null   uint8  \n",
      " 7   cmonth_4.0   7891 non-null   uint8  \n",
      " 8   cmonth_5.0   7891 non-null   uint8  \n",
      " 9   cmonth_6.0   7891 non-null   uint8  \n",
      " 10  cmonth_7.0   7891 non-null   uint8  \n",
      " 11  cmonth_8.0   7891 non-null   uint8  \n",
      " 12  cmonth_9.0   7891 non-null   uint8  \n",
      " 13  cmonth_10.0  7891 non-null   uint8  \n",
      " 14  cmonth_11.0  7891 non-null   uint8  \n",
      " 15  cmonth_12.0  7891 non-null   uint8  \n",
      " 16  chour_1.0    7891 non-null   uint8  \n",
      " 17  chour_2.0    7891 non-null   uint8  \n",
      " 18  chour_3.0    7891 non-null   uint8  \n",
      " 19  chour_4.0    7891 non-null   uint8  \n",
      " 20  chour_5.0    7891 non-null   uint8  \n",
      " 21  chour_6.0    7891 non-null   uint8  \n",
      " 22  chour_7.0    7891 non-null   uint8  \n",
      " 23  chour_8.0    7891 non-null   uint8  \n",
      " 24  chour_9.0    7891 non-null   uint8  \n",
      " 25  chour_10.0   7891 non-null   uint8  \n",
      " 26  chour_11.0   7891 non-null   uint8  \n",
      " 27  chour_12.0   7891 non-null   uint8  \n",
      " 28  chour_13.0   7891 non-null   uint8  \n",
      " 29  chour_14.0   7891 non-null   uint8  \n",
      " 30  chour_15.0   7891 non-null   uint8  \n",
      " 31  chour_16.0   7891 non-null   uint8  \n",
      " 32  chour_17.0   7891 non-null   uint8  \n",
      " 33  chour_18.0   7891 non-null   uint8  \n",
      " 34  chour_19.0   7891 non-null   uint8  \n",
      " 35  chour_20.0   7891 non-null   uint8  \n",
      " 36  chour_21.0   7891 non-null   uint8  \n",
      " 37  chour_22.0   7891 non-null   uint8  \n",
      " 38  chour_23.0   7891 non-null   uint8  \n",
      "dtypes: float64(1), int32(3), uint8(35)\n",
      "memory usage: 485.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_dumt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab11e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variables\n",
    "y_dumt = df_dumt.pop('target')\n",
    "y_dum = df_dum.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "360af620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split categorical seasonality dataset\n",
    "df_numt = df_num.iloc[-sample:]\n",
    "df_num = df_num.iloc[:-sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d66f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variables\n",
    "y_numt = df_numt.pop('target')\n",
    "y_num = df_num.pop('target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8673921",
   "metadata": {},
   "source": [
    "### Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b2fa979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using MinMaxScaler due to the comparison with the dummy seasonality data\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8435036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the dummies dataset\n",
    "X_dum = scaler.fit_transform(df_dum)\n",
    "X_dumt = scaler.transform(df_dumt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58029827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the categorical dataset\n",
    "X_num = scaler.fit_transform(df_num)\n",
    "X_numt = scaler.transform(df_numt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "932d1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make an inner and outer validation scheme for Nested Cross-Validation\n",
    "time_split = TimeSeriesSplit(n_splits = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4024bd9",
   "metadata": {},
   "source": [
    "# Randomized Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6822f2",
   "metadata": {},
   "source": [
    "The first optimization is undertaken on the **dummy seasonality** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3d9a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "lasso = Lasso(random_state=11)\n",
    "\n",
    "las_dist = {'fit_intercept': [1, 0],\n",
    "            'alpha': uniform(0.001, 2)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea3a0565",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_las = RandomizedSearchCV(lasso, las_dist, cv=time_split, scoring='neg_mean_squared_error', \n",
    "                            n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "275e4b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=Lasso(random_state=11), n_jobs=-1,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C855A30>,\n",
       "                                        'fit_intercept': [1, 0]},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_las.fit(X_dum, y_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85b8e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "ridge = Ridge(random_state=11)\n",
    "\n",
    "rdg_dist = {'fit_intercept': [1, 0],\n",
    "            'solver': ['lsqr', 'sag', 'cholesky'],\n",
    "            'alpha': uniform(0.001, 2)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4a7d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rdg = RandomizedSearchCV(ridge, rdg_dist, cv=time_split, scoring='neg_mean_squared_error', \n",
    "                            n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c47c666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=Ridge(random_state=11), n_jobs=-1,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C6E7880>,\n",
       "                                        'fit_intercept': [1, 0],\n",
       "                                        'solver': ['lsqr', 'sag', 'cholesky']},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rdg.fit(X_dum, y_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fb9ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(random_state=11)\n",
    "\n",
    "rf_dist = {'n_estimators': randint(50, 500),\n",
    "           'min_samples_split': randint(2, 9),\n",
    "           'max_features': ['auto', 'log2', 'sqrt']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "118453fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf = RandomizedSearchCV(rf, rf_dist, cv=time_split, scoring = 'neg_mean_squared_error', \n",
    "                           n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21a9fbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=RandomForestRegressor(random_state=11), n_jobs=-1,\n",
       "                   param_distributions={'max_features': ['auto', 'log2',\n",
       "                                                         'sqrt'],\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C855760>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C1F8100>},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf.fit(X_dum, y_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1629a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG Boost Regressor\n",
    "xgb = xgb.XGBRegressor(objective='reg:squarederror', random_state=11)\n",
    "\n",
    "xgb_dist = {'n_estimators': randint(50, 500),\n",
    "            'subsample': [0.5, 0.7, 1],\n",
    "            'eta': uniform(0.05, 1.0),\n",
    "            'gamma': randint(0, 300)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dddbd9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_xgb = RandomizedSearchCV(xgb, xgb_dist, cv=time_split, scoring = 'neg_mean_squared_error', \n",
    "                            n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bdc67e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_w...\n",
       "                                          verbosity=None),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'eta': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C1F8790>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C2699A0>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C269610>,\n",
       "                                        'subsample': [0.5, 0.7, 1]},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_xgb.fit(X_dum, y_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07bd576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regressor\n",
    "svm = SVR()\n",
    "\n",
    "svm_dist = {'kernel': ['rbf', 'linear', 'poly'],\n",
    "            'gamma': ['scale', 'auto', 0.2], \n",
    "            'epsilon': uniform(0.01, 3),\n",
    "            'C': uniform(0.1, 5)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7db2d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_svm = RandomizedSearchCV(svm, svm_dist, cv=time_split, scoring = 'neg_mean_squared_error', \n",
    "                            n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41f121ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=SVR(), n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C1F0F70>,\n",
       "                                        'epsilon': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C2944F0>,\n",
       "                                        'gamma': ['scale', 'auto', 0.2],\n",
       "                                        'kernel': ['rbf', 'linear', 'poly']},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_svm.fit(X_dum, y_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "182be51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Layer Perceptron\n",
    "# Typically 1-2 hidden layers are adequate, and the optimal size of the first hidden layer is usually... \n",
    "# between that of the input and the output layers, or 38 and 1 in this case (38 is the max with all the time dummies)\n",
    "\n",
    "mlp = MLPRegressor(early_stopping=True, max_iter=10000, random_state=11)\n",
    "\n",
    "mlp_dist = {'hidden_layer_sizes': [(15,), (22,), (30,), (15,8), (22,8), (22,15), (30,8), (30,15)],\n",
    "            'alpha': uniform(0.01, 5),\n",
    "            'activation': ['relu', 'tanh'],\n",
    "            'solver': ['lbfgs', 'adam']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0e360ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_mlp = RandomizedSearchCV(mlp, mlp_dist, cv=time_split, scoring = 'neg_mean_squared_error', \n",
    "                            n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1674697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=MLPRegressor(early_stopping=True, max_iter=10000,\n",
       "                                          random_state=11),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['relu', 'tanh'],\n",
       "                                        'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C1F09A0>,\n",
       "                                        'hidden_layer_sizes': [(15,), (22,),\n",
       "                                                               (30,), (15, 8),\n",
       "                                                               (22, 8),\n",
       "                                                               (22, 15),\n",
       "                                                               (30, 8),\n",
       "                                                               (30, 15)],\n",
       "                                        'solver': ['lbfgs', 'adam']},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_mlp.fit(X_dum, y_dum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1081d98",
   "metadata": {},
   "source": [
    "### Best parameters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08b5bebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.5750998609261154, 'fit_intercept': 1}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_las.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8c6c1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1709174847023479, 'fit_intercept': 1, 'solver': 'sag'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rdg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae1cfa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto', 'min_samples_split': 6, 'n_estimators': 171}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a420e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.2844429935096328, 'gamma': 295, 'n_estimators': 461, 'subsample': 1}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed2c0cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5.071605234485836,\n",
       " 'epsilon': 0.8856124221777116,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'poly'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "812cae06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 4.879482142248864,\n",
       " 'hidden_layer_sizes': (30, 15),\n",
       " 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_mlp.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e0ff0",
   "metadata": {},
   "source": [
    "# Cross-Validation & Scoring on Dummies Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0357e3",
   "metadata": {},
   "source": [
    "### Cross-validation on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9b48c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "las_scores_dum = cross_val_score(rs_las, X_dum, y_dum, cv = time_split, n_jobs=-1, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d53cc089",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_scores_dum = cross_val_score(rs_rdg, X_dum, y_dum, cv = time_split, n_jobs=-1, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b500e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores_dum = cross_val_score(rs_rf, X_dum, y_dum, cv = time_split, n_jobs=-1, \n",
    "                                scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1c248ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "xgb_scores_dum = cross_val_score(rs_xgb, X_dum, y_dum, cv = time_split, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "787a4904",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_scores_dum = cross_val_score(rs_svm, X_dum, y_dum, cv = time_split, n_jobs=-1, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc7b5a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_scores_dum = cross_val_score(rs_mlp, X_dum, y_dum, cv = time_split, n_jobs=-1, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a24dfc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dict_dum = {\n",
    "    'Lasso Regression': -np.round(las_scores_dum.mean(), 4),\n",
    "    'Ridge Regression': -np.round(rdg_scores_dum.mean(), 4),\n",
    "    'Random Forest': -np.round(rf_scores_dum.mean(), 4),\n",
    "    'Xtreme Gradient Boost': -np.round(xgb_scores_dum.mean(), 4),\n",
    "    'Support Vector Machine': -np.round(svm_scores_dum.mean(), 4),\n",
    "    'Multi-Layer Perceptron': -np.round(mlp_scores_dum.mean(), 4),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cca4fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_dum = pd.DataFrame({'Model': cv_dict_dum.keys(), 'Average MAE': cv_dict_dum.values()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab411f7",
   "metadata": {},
   "source": [
    "### Scoring test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0240a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_scoring(X, y, reg_dict):\n",
    "    '''\n",
    "    Objective: Cycles through a dictionary of trained models, using them to make predictions, scores those \n",
    "    predictions on MAE, MSE & RMSE, and generates DataFrames of the scores and model predictions respectively\n",
    "    \n",
    "    X: DataFrame containing the explanatory variables\n",
    "    \n",
    "    y: Target variable\n",
    "    \n",
    "    reg_dict: Dictionary of trained/fitted models\n",
    "    '''\n",
    "    \n",
    "    test1_scores = []\n",
    "    test2_scores = []\n",
    "    \n",
    "    df_pred = pd.DataFrame(columns=reg_dict.keys()) # Columns of DF will accord with reg_dict keys\n",
    "    \n",
    "    # Loop through Dictionary items\n",
    "    for key, reg in reg_dict.items():\n",
    "        \n",
    "        pred_y = reg.predict(X)\n",
    "        df_pred[key] = pd.Series(pred_y).transpose()\n",
    "        \n",
    "        # Computing test scores for each model\n",
    "        test1_scores.append(round(mean_absolute_error(y, pred_y), 4))\n",
    "        test2_scores.append(round(mean_squared_error(y, pred_y, squared=False), 4))\n",
    "        \n",
    "    # Generate results DataFrame\n",
    "    results = pd.DataFrame({'Model': list(reg_dict.keys()), \n",
    "                            'Mean Absolute Error': test1_scores,\n",
    "                            'Root Mean Squared Error': test2_scores\n",
    "                            })\n",
    "    \n",
    "    # Add target variable to the DataFrame of predictions\n",
    "    df_pred['Target'] = y.tolist()\n",
    "    \n",
    "    return results, df_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ea16c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of TRAINED models\n",
    "reg_dict = {\n",
    "    'Lasso Regression': rs_las,\n",
    "    'Ridge Regression': rs_rdg,\n",
    "    'Random Forest': rs_rf,\n",
    "    'Xtreme Gradient Boost': rs_xgb,\n",
    "    'Support Vector Machine': rs_svm,\n",
    "    'Multi-Layer Perceptron': rs_mlp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "700c41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dum, df_pred_dum = reg_scoring(X_dumt, y_dumt, reg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c3f61c",
   "metadata": {},
   "source": [
    "# Refit on Numerical Seasonality Data & Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b57e6a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=Lasso(random_state=11), n_jobs=-1,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C855A30>,\n",
       "                                        'fit_intercept': [1, 0]},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_las.fit(X_num, y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65b7b7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=Ridge(random_state=11), n_jobs=-1,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C6E7880>,\n",
       "                                        'fit_intercept': [1, 0],\n",
       "                                        'solver': ['lsqr', 'sag', 'cholesky']},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rdg.fit(X_num, y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44dc5a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=RandomForestRegressor(random_state=11), n_jobs=-1,\n",
       "                   param_distributions={'max_features': ['auto', 'log2',\n",
       "                                                         'sqrt'],\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C855760>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C1F8100>},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf.fit(X_num, y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8952c8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_w...\n",
       "                                          verbosity=None),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'eta': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C1F8790>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C2699A0>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C269610>,\n",
       "                                        'subsample': [0.5, 0.7, 1]},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_xgb.fit(X_num, y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "81f06037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=SVR(), n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C1F0F70>,\n",
       "                                        'epsilon': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C2944F0>,\n",
       "                                        'gamma': ['scale', 'auto', 0.2],\n",
       "                                        'kernel': ['rbf', 'linear', 'poly']},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_svm.fit(X_num, y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08fa8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=MLPRegressor(early_stopping=True, max_iter=10000,\n",
       "                                          random_state=11),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['relu', 'tanh'],\n",
       "                                        'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EA8C1F09A0>,\n",
       "                                        'hidden_layer_sizes': [(15,), (22,),\n",
       "                                                               (30,), (15, 8),\n",
       "                                                               (22, 8),\n",
       "                                                               (22, 15),\n",
       "                                                               (30, 8),\n",
       "                                                               (30, 15)],\n",
       "                                        'solver': ['lbfgs', 'adam']},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_mlp.fit(X_num, y_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f02272d",
   "metadata": {},
   "source": [
    "### Best parameters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea715359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.4265774130674401, 'fit_intercept': 1}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_las.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97868f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.023670267405791923, 'fit_intercept': 1, 'solver': 'sag'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rdg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7c2e8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 184}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "622fcd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.05987395786498813,\n",
       " 'gamma': 68,\n",
       " 'n_estimators': 427,\n",
       " 'subsample': 0.5}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e49e7dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 4.718712691702722,\n",
       " 'epsilon': 0.2726025400944049,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'linear'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05bd2886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 2.4111360628432275,\n",
       " 'hidden_layer_sizes': (30, 15),\n",
       " 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_mlp.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3098e8c",
   "metadata": {},
   "source": [
    "# Cross-Validation & Scoring on Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "abcb7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "las_scores_num = cross_val_score(rs_las, X_num, y_num, cv = time_split, n_jobs=-1, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61842bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_scores_num = cross_val_score(rs_rdg, X_num, y_num, cv = time_split, n_jobs=-1, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0ffce6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores_num = cross_val_score(rs_rf, X_num, y_num, cv = time_split, n_jobs=-1, \n",
    "                                scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d836b5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "xgb_scores_num = cross_val_score(rs_xgb, X_num, y_num, cv = time_split, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0961a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_scores_num = cross_val_score(rs_svm, X_num, y_num, cv = time_split, n_jobs=-1, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e02599b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_scores_num = cross_val_score(rs_mlp, X_num, y_num, cv = time_split, n_jobs=-1, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "97b3c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dict_num = {\n",
    "    'Lasso Regression': -np.round(las_scores_num.mean(), 4),\n",
    "    'Ridge Regression': -np.round(rdg_scores_num.mean(), 4),\n",
    "    'Random Forest': -np.round(rf_scores_num.mean(), 4),\n",
    "    'Xtreme Gradient Boost': -np.round(xgb_scores_num.mean(), 4),\n",
    "    'Support Vector Machine': -np.round(svm_scores_num.mean(), 4),\n",
    "    'Multi-Layer Perceptron': -np.round(mlp_scores_num.mean(), 4),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f3c29935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_num = pd.DataFrame({'Model': cv_dict_num.keys(), 'Average MAE': cv_dict_num.values()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598ee3bf",
   "metadata": {},
   "source": [
    "### Scoring on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e08c9411",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_num, df_pred_num = reg_scoring(X_numt, y_numt, reg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "712c1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_dum['date'] = df_dumt.index\n",
    "df_pred_num['date'] = df_numt.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1a22c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pred_dum.to_csv(r'C:\\\\ny_pred_dum.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6aaee5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pred_num.to_csv(r'C:\\\\ny_pred_num.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf5085",
   "metadata": {},
   "source": [
    "# Comparative Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f28fb10",
   "metadata": {},
   "source": [
    "### Cross-validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7a0ea6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Average MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>258.2085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>252.8884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>207.8334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xtreme Gradient Boost</td>\n",
       "      <td>143.0849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>1189.7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multi-Layer Perceptron</td>\n",
       "      <td>194.7623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Average MAE\n",
       "0        Lasso Regression     258.2085\n",
       "1        Ridge Regression     252.8884\n",
       "2           Random Forest     207.8334\n",
       "3   Xtreme Gradient Boost     143.0849\n",
       "4  Support Vector Machine    1189.7579\n",
       "5  Multi-Layer Perceptron     194.7623"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a8b72082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Average MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>570.5975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>571.5516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>140.0205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xtreme Gradient Boost</td>\n",
       "      <td>132.8851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>1557.9531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multi-Layer Perceptron</td>\n",
       "      <td>328.7591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Average MAE\n",
       "0        Lasso Regression     570.5975\n",
       "1        Ridge Regression     571.5516\n",
       "2           Random Forest     140.0205\n",
       "3   Xtreme Gradient Boost     132.8851\n",
       "4  Support Vector Machine    1557.9531\n",
       "5  Multi-Layer Perceptron     328.7591"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0b46fd",
   "metadata": {},
   "source": [
    "### Test data scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "12fb2d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>240.4340</td>\n",
       "      <td>309.8406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>240.7296</td>\n",
       "      <td>308.9430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>177.0530</td>\n",
       "      <td>261.8896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xtreme Gradient Boost</td>\n",
       "      <td>121.2744</td>\n",
       "      <td>162.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>1012.3491</td>\n",
       "      <td>1351.1937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multi-Layer Perceptron</td>\n",
       "      <td>109.0606</td>\n",
       "      <td>146.8422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Mean Absolute Error  Root Mean Squared Error\n",
       "0        Lasso Regression             240.4340                 309.8406\n",
       "1        Ridge Regression             240.7296                 308.9430\n",
       "2           Random Forest             177.0530                 261.8896\n",
       "3   Xtreme Gradient Boost             121.2744                 162.9995\n",
       "4  Support Vector Machine            1012.3491                1351.1937\n",
       "5  Multi-Layer Perceptron             109.0606                 146.8422"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7ce69b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>524.9513</td>\n",
       "      <td>669.4484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>525.1390</td>\n",
       "      <td>669.4783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>126.7053</td>\n",
       "      <td>172.8285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xtreme Gradient Boost</td>\n",
       "      <td>114.2283</td>\n",
       "      <td>152.9164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>895.7971</td>\n",
       "      <td>1143.5224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multi-Layer Perceptron</td>\n",
       "      <td>185.6066</td>\n",
       "      <td>247.6233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Mean Absolute Error  Root Mean Squared Error\n",
       "0        Lasso Regression             524.9513                 669.4484\n",
       "1        Ridge Regression             525.1390                 669.4783\n",
       "2           Random Forest             126.7053                 172.8285\n",
       "3   Xtreme Gradient Boost             114.2283                 152.9164\n",
       "4  Support Vector Machine             895.7971                1143.5224\n",
       "5  Multi-Layer Perceptron             185.6066                 247.6233"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84069f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
