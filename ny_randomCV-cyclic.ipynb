{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2cf941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b334c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3954e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "756465d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv('C:\\\\ny_engineered.csv')\n",
    "df = pd.DataFrame(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b31078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c61431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting DateTime index\n",
    "df['date'] = pd.to_datetime(df.date)\n",
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44c30f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 39455 entries, 2015-07-02 00:00:00 to 2019-12-31 22:00:00\n",
      "Data columns (total 45 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   load         39455 non-null  float64\n",
      " 1   temp         39455 non-null  float64\n",
      " 2   humid        39455 non-null  float64\n",
      " 3   target       39455 non-null  float64\n",
      " 4   cwkend       39455 non-null  float64\n",
      " 5   mth_sin      39455 non-null  float64\n",
      " 6   mth_cos      39455 non-null  float64\n",
      " 7   hour_sin     39455 non-null  float64\n",
      " 8   hour_cos     39455 non-null  float64\n",
      " 9   hour_num     39455 non-null  float64\n",
      " 10  mth_num      39455 non-null  float64\n",
      " 11  cmonth_2.0   39455 non-null  int64  \n",
      " 12  cmonth_3.0   39455 non-null  int64  \n",
      " 13  cmonth_4.0   39455 non-null  int64  \n",
      " 14  cmonth_5.0   39455 non-null  int64  \n",
      " 15  cmonth_6.0   39455 non-null  int64  \n",
      " 16  cmonth_7.0   39455 non-null  int64  \n",
      " 17  cmonth_8.0   39455 non-null  int64  \n",
      " 18  cmonth_9.0   39455 non-null  int64  \n",
      " 19  cmonth_10.0  39455 non-null  int64  \n",
      " 20  cmonth_11.0  39455 non-null  int64  \n",
      " 21  cmonth_12.0  39455 non-null  int64  \n",
      " 22  chour_1.0    39455 non-null  int64  \n",
      " 23  chour_2.0    39455 non-null  int64  \n",
      " 24  chour_3.0    39455 non-null  int64  \n",
      " 25  chour_4.0    39455 non-null  int64  \n",
      " 26  chour_5.0    39455 non-null  int64  \n",
      " 27  chour_6.0    39455 non-null  int64  \n",
      " 28  chour_7.0    39455 non-null  int64  \n",
      " 29  chour_8.0    39455 non-null  int64  \n",
      " 30  chour_9.0    39455 non-null  int64  \n",
      " 31  chour_10.0   39455 non-null  int64  \n",
      " 32  chour_11.0   39455 non-null  int64  \n",
      " 33  chour_12.0   39455 non-null  int64  \n",
      " 34  chour_13.0   39455 non-null  int64  \n",
      " 35  chour_14.0   39455 non-null  int64  \n",
      " 36  chour_15.0   39455 non-null  int64  \n",
      " 37  chour_16.0   39455 non-null  int64  \n",
      " 38  chour_17.0   39455 non-null  int64  \n",
      " 39  chour_18.0   39455 non-null  int64  \n",
      " 40  chour_19.0   39455 non-null  int64  \n",
      " 41  chour_20.0   39455 non-null  int64  \n",
      " 42  chour_21.0   39455 non-null  int64  \n",
      " 43  chour_22.0   39455 non-null  int64  \n",
      " 44  chour_23.0   39455 non-null  int64  \n",
      "dtypes: float64(11), int64(34)\n",
      "memory usage: 13.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e78e1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the integer variables to int32 type to reduce memory usage\n",
    "df[['load', 'humid', 'target', 'hour_num', 'mth_num']] = \\\n",
    "    df[['load', 'humid', 'target', 'hour_num', 'mth_num']].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cfc8228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dummy variables to uint8 type to reduce memory usage\n",
    "df[['cmonth_2.0', 'cmonth_3.0', 'cmonth_4.0', 'cmonth_5.0', 'cmonth_6.0', 'cmonth_7.0', 'cmonth_8.0', 'cmonth_9.0',\n",
    "    'cmonth_10.0', 'cmonth_11.0', 'cmonth_12.0', 'chour_1.0', 'chour_2.0', 'chour_3.0', 'chour_4.0', 'chour_5.0',\n",
    "    'chour_6.0', 'chour_7.0', 'chour_8.0', 'chour_9.0', 'chour_10.0', 'chour_11.0', 'chour_12.0', 'chour_13.0', \n",
    "    'chour_14.0', 'chour_15.0', 'chour_16.0', 'chour_17.0', 'chour_18.0', 'chour_19.0', 'chour_20.0', 'chour_21.0',\n",
    "    'chour_22.0', 'chour_23.0', 'cwkend']] = \\\n",
    "    df[['cmonth_2.0', 'cmonth_3.0', 'cmonth_4.0', 'cmonth_5.0', 'cmonth_6.0', 'cmonth_7.0', 'cmonth_8.0', \n",
    "        'cmonth_9.0', 'cmonth_10.0', 'cmonth_11.0', 'cmonth_12.0', 'chour_1.0', 'chour_2.0', 'chour_3.0',\n",
    "        'chour_4.0', 'chour_5.0', 'chour_6.0', 'chour_7.0', 'chour_8.0', 'chour_9.0', 'chour_10.0', 'chour_11.0',\n",
    "        'chour_12.0', 'chour_13.0', 'chour_14.0', 'chour_15.0', 'chour_16.0', 'chour_17.0', 'chour_18.0',\n",
    "        'chour_19.0', 'chour_20.0', 'chour_21.0', 'chour_22.0', 'chour_23.0', 'cwkend']].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d93f026c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 39455 entries, 2015-07-02 00:00:00 to 2019-12-31 22:00:00\n",
      "Data columns (total 45 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   load         39455 non-null  int32  \n",
      " 1   temp         39455 non-null  float64\n",
      " 2   humid        39455 non-null  int32  \n",
      " 3   target       39455 non-null  int32  \n",
      " 4   cwkend       39455 non-null  uint8  \n",
      " 5   mth_sin      39455 non-null  float64\n",
      " 6   mth_cos      39455 non-null  float64\n",
      " 7   hour_sin     39455 non-null  float64\n",
      " 8   hour_cos     39455 non-null  float64\n",
      " 9   hour_num     39455 non-null  int32  \n",
      " 10  mth_num      39455 non-null  int32  \n",
      " 11  cmonth_2.0   39455 non-null  uint8  \n",
      " 12  cmonth_3.0   39455 non-null  uint8  \n",
      " 13  cmonth_4.0   39455 non-null  uint8  \n",
      " 14  cmonth_5.0   39455 non-null  uint8  \n",
      " 15  cmonth_6.0   39455 non-null  uint8  \n",
      " 16  cmonth_7.0   39455 non-null  uint8  \n",
      " 17  cmonth_8.0   39455 non-null  uint8  \n",
      " 18  cmonth_9.0   39455 non-null  uint8  \n",
      " 19  cmonth_10.0  39455 non-null  uint8  \n",
      " 20  cmonth_11.0  39455 non-null  uint8  \n",
      " 21  cmonth_12.0  39455 non-null  uint8  \n",
      " 22  chour_1.0    39455 non-null  uint8  \n",
      " 23  chour_2.0    39455 non-null  uint8  \n",
      " 24  chour_3.0    39455 non-null  uint8  \n",
      " 25  chour_4.0    39455 non-null  uint8  \n",
      " 26  chour_5.0    39455 non-null  uint8  \n",
      " 27  chour_6.0    39455 non-null  uint8  \n",
      " 28  chour_7.0    39455 non-null  uint8  \n",
      " 29  chour_8.0    39455 non-null  uint8  \n",
      " 30  chour_9.0    39455 non-null  uint8  \n",
      " 31  chour_10.0   39455 non-null  uint8  \n",
      " 32  chour_11.0   39455 non-null  uint8  \n",
      " 33  chour_12.0   39455 non-null  uint8  \n",
      " 34  chour_13.0   39455 non-null  uint8  \n",
      " 35  chour_14.0   39455 non-null  uint8  \n",
      " 36  chour_15.0   39455 non-null  uint8  \n",
      " 37  chour_16.0   39455 non-null  uint8  \n",
      " 38  chour_17.0   39455 non-null  uint8  \n",
      " 39  chour_18.0   39455 non-null  uint8  \n",
      " 40  chour_19.0   39455 non-null  uint8  \n",
      " 41  chour_20.0   39455 non-null  uint8  \n",
      " 42  chour_21.0   39455 non-null  uint8  \n",
      " 43  chour_22.0   39455 non-null  uint8  \n",
      " 44  chour_23.0   39455 non-null  uint8  \n",
      "dtypes: float64(5), int32(5), uint8(35)\n",
      "memory usage: 3.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd528f",
   "metadata": {},
   "source": [
    "# Create Cyclic Seasonality Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37b67249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyc = df.drop(['cmonth_2.0', 'cmonth_3.0', 'cmonth_4.0', 'cmonth_5.0', 'cmonth_6.0', 'cmonth_7.0', \n",
    "                  'cmonth_8.0', 'cmonth_9.0', 'cmonth_10.0', 'cmonth_11.0', 'cmonth_12.0', 'chour_1.0', \n",
    "                  'chour_2.0', 'chour_3.0', 'chour_4.0', 'chour_5.0', 'chour_6.0', 'chour_7.0', \n",
    "                  'chour_8.0', 'chour_9.0', 'chour_10.0', 'chour_11.0', 'chour_12.0', 'chour_13.0', \n",
    "                  'chour_14.0', 'chour_15.0', 'chour_16.0', 'chour_17.0', 'chour_18.0', 'chour_19.0', \n",
    "                  'chour_20.0', 'chour_21.0', 'chour_22.0', 'chour_23.0', 'mth_num', 'hour_num'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c6e50",
   "metadata": {},
   "source": [
    "# Preparing Data for Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2087498b",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "696d6fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set test set at 20% of data\n",
    "sample = int(len(df)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9866ee92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7891"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "367bfc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyct = df_cyc.iloc[-sample:]\n",
    "df_cyc = df_cyc.iloc[:-sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b87180fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 31564 entries, 2015-07-02 00:00:00 to 2019-02-06 03:00:00\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   load      31564 non-null  int32  \n",
      " 1   temp      31564 non-null  float64\n",
      " 2   humid     31564 non-null  int32  \n",
      " 3   target    31564 non-null  int32  \n",
      " 4   cwkend    31564 non-null  uint8  \n",
      " 5   mth_sin   31564 non-null  float64\n",
      " 6   mth_cos   31564 non-null  float64\n",
      " 7   hour_sin  31564 non-null  float64\n",
      " 8   hour_cos  31564 non-null  float64\n",
      "dtypes: float64(5), int32(3), uint8(1)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_cyc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90763a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 7891 entries, 2019-02-06 04:00:00 to 2019-12-31 22:00:00\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   load      7891 non-null   int32  \n",
      " 1   temp      7891 non-null   float64\n",
      " 2   humid     7891 non-null   int32  \n",
      " 3   target    7891 non-null   int32  \n",
      " 4   cwkend    7891 non-null   uint8  \n",
      " 5   mth_sin   7891 non-null   float64\n",
      " 6   mth_cos   7891 non-null   float64\n",
      " 7   hour_sin  7891 non-null   float64\n",
      " 8   hour_cos  7891 non-null   float64\n",
      "dtypes: float64(5), int32(3), uint8(1)\n",
      "memory usage: 470.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_cyct.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c68f4302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variables, which will be the SAME for all the various datasets\n",
    "y_cyct = df_cyct.pop('target')\n",
    "y_cyc = df_cyc.pop('target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8673921",
   "metadata": {},
   "source": [
    "### Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b2fa979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using MinMaxScaler due to the comparison with the dummy seasonality treatment\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b0389e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the cyclic dataset\n",
    "X_cyc = scaler.fit_transform(df_cyc)\n",
    "X_cyct = scaler.transform(df_cyct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "932d1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make an inner and outer validation scheme for Nested Cross-Validation\n",
    "time_split = TimeSeriesSplit(n_splits = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4024bd9",
   "metadata": {},
   "source": [
    "# Randomized Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6822f2",
   "metadata": {},
   "source": [
    "Optimization on the **cyclic seasonality** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3d9a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "lasso = Lasso(random_state=11)\n",
    "\n",
    "las_dist = {'fit_intercept': [1, 0],\n",
    "            'alpha': uniform(0.001, 2)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea3a0565",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_las = RandomizedSearchCV(lasso, las_dist, cv=time_split, scoring='neg_mean_squared_error', \n",
    "                            n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "275e4b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=Lasso(random_state=11), n_jobs=-1,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021CA01E6D30>,\n",
       "                                        'fit_intercept': [1, 0]},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_las.fit(X_cyc, y_cyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85b8e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "ridge = Ridge(random_state=11)\n",
    "\n",
    "rdg_dist = {'fit_intercept': [1, 0],\n",
    "            'solver': ['lsqr', 'sag', 'cholesky'],\n",
    "            'alpha': uniform(0.001, 2)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4a7d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rdg = RandomizedSearchCV(ridge, rdg_dist, cv=time_split, scoring='neg_mean_squared_error', \n",
    "                            n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c47c666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=Ridge(random_state=11), n_jobs=-1,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021CA0126850>,\n",
       "                                        'fit_intercept': [1, 0],\n",
       "                                        'solver': ['lsqr', 'sag', 'cholesky']},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rdg.fit(X_cyc, y_cyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fb9ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(random_state=11)\n",
    "\n",
    "rf_dist = {'n_estimators': randint(50, 500),\n",
    "           'min_samples_split': randint(2, 9),\n",
    "           'max_features': ['auto', 'log2', 'sqrt']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "118453fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf = RandomizedSearchCV(rf, rf_dist, cv=time_split, scoring = 'neg_mean_squared_error', \n",
    "                           n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21a9fbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=RandomForestRegressor(random_state=11), n_jobs=-1,\n",
       "                   param_distributions={'max_features': ['auto', 'log2',\n",
       "                                                         'sqrt'],\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021C9FFE3EE0>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021C9FAC3430>},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf.fit(X_cyc, y_cyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1629a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG Boost Regressor\n",
    "xgb = xgb.XGBRegressor(objective='reg:squarederror', random_state=11)\n",
    "\n",
    "xgb_dist = {'n_estimators': randint(50, 500),\n",
    "            'subsample': [0.5, 0.7, 1],\n",
    "            'eta': uniform(0.05, 1.0),\n",
    "            'gamma': randint(0, 300)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dddbd9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_xgb = RandomizedSearchCV(xgb, xgb_dist, cv=time_split, scoring = 'neg_mean_squared_error', \n",
    "                            n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdc67e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_w...\n",
       "                                          verbosity=None),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'eta': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021C9FB57760>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021C9FB57D30>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021C9FB76BB0>,\n",
       "                                        'subsample': [0.5, 0.7, 1]},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_xgb.fit(X_cyc, y_cyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07bd576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regressor\n",
    "svm = SVR()\n",
    "\n",
    "svm_dist = {'kernel': ['rbf', 'linear', 'poly'],\n",
    "            'gamma': ['scale', 'auto', 0.2], \n",
    "            'epsilon': uniform(0.01, 3),\n",
    "            'C': uniform(0.1, 5)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7db2d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_svm = RandomizedSearchCV(svm, svm_dist, cv=time_split, scoring = 'neg_mean_squared_error', \n",
    "                            n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41f121ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=SVR(), n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021C9FB687C0>,\n",
       "                                        'epsilon': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021C9FB619A0>,\n",
       "                                        'gamma': ['scale', 'auto', 0.2],\n",
       "                                        'kernel': ['rbf', 'linear', 'poly']},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_svm.fit(X_cyc, y_cyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "182be51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Layer Perceptron\n",
    "# Typically 1-2 hidden layers are adequate, and the optimal size of the first hidden layer is usually... \n",
    "# between that of the input and the output layers, or 38 and 1 in this case (38 is the max with all the time dummies)\n",
    "\n",
    "mlp = MLPRegressor(early_stopping=True, max_iter=10000, random_state=11)\n",
    "\n",
    "mlp_dist = {'hidden_layer_sizes': [(15,), (22,), (30,), (15,8), (22,8), (22,15), (30,8), (30,15)],\n",
    "            'alpha': uniform(0.01, 5),\n",
    "            'activation': ['relu', 'tanh'],\n",
    "            'solver': ['lbfgs', 'adam']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0e360ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_mlp = RandomizedSearchCV(mlp, mlp_dist, cv=time_split, scoring = 'neg_mean_squared_error', \n",
    "                            n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1674697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=MLPRegressor(early_stopping=True, max_iter=10000,\n",
       "                                          random_state=11),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['relu', 'tanh'],\n",
       "                                        'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021C9FB868E0>,\n",
       "                                        'hidden_layer_sizes': [(15,), (22,),\n",
       "                                                               (30,), (15, 8),\n",
       "                                                               (22, 8),\n",
       "                                                               (22, 15),\n",
       "                                                               (30, 8),\n",
       "                                                               (30, 15)],\n",
       "                                        'solver': ['lbfgs', 'adam']},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_mlp.fit(X_cyc, y_cyc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1081d98",
   "metadata": {},
   "source": [
    "### Best parameters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08b5bebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.5227665708609351, 'fit_intercept': 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_las.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8c6c1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.47675736919835654, 'fit_intercept': 1, 'solver': 'lsqr'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rdg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae1cfa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'log2', 'min_samples_split': 4, 'n_estimators': 414}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a420e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.2109542143654975, 'gamma': 148, 'n_estimators': 492, 'subsample': 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed2c0cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 4.974239991626877,\n",
       " 'epsilon': 1.2819822983393951,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'poly'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "812cae06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 2.2756697508499046,\n",
       " 'hidden_layer_sizes': (30, 15),\n",
       " 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_mlp.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e0ff0",
   "metadata": {},
   "source": [
    "# Cross-Validation & Scoring on Cyclic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0357e3",
   "metadata": {},
   "source": [
    "### Cross-validation on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9b48c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "las_scores_cyc = cross_val_score(rs_las, X_cyc, y_cyc, cv = time_split, n_jobs=-1, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d53cc089",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_scores_cyc = cross_val_score(rs_rdg, X_cyc, y_cyc, cv = time_split, n_jobs=-1, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b500e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores_cyc = cross_val_score(rs_rf, X_cyc, y_cyc, cv = time_split, n_jobs=-1, \n",
    "                                scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1c248ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "xgb_scores_cyc = cross_val_score(rs_xgb, X_cyc, y_cyc, cv = time_split, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "787a4904",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_scores_cyc = cross_val_score(rs_svm, X_cyc, y_cyc, cv = time_split, n_jobs=-1, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc7b5a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_scores_cyc = cross_val_score(rs_mlp, X_cyc, y_cyc, cv = time_split, n_jobs=-1, \n",
    "                                 scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a24dfc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dict_cyc = {\n",
    "    'Lasso Regression': -np.round(las_scores_cyc.mean(), 4),\n",
    "    'Ridge Regression': -np.round(rdg_scores_cyc.mean(), 4),\n",
    "    'Random Forest': -np.round(rf_scores_cyc.mean(), 4),\n",
    "    'Xtreme Gradient Boost': -np.round(xgb_scores_cyc.mean(), 4),\n",
    "    'Support Vector Machine': -np.round(svm_scores_cyc.mean(), 4),\n",
    "    'Multi-Layer Perceptron': -np.round(mlp_scores_cyc.mean(), 4),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cca4fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_cyc = pd.DataFrame({'Model': cv_dict_cyc.keys(), 'Average MAE': cv_dict_cyc.values()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab411f7",
   "metadata": {},
   "source": [
    "### Scoring test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0240a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_scoring(X, y, reg_dict):\n",
    "    '''\n",
    "    Objective: Cycles through a dictionary of trained models, using them to make predictions, scores those \n",
    "    predictions on MAE, MSE & RMSE, and generates DataFrames of the scores and model predictions respectively\n",
    "    \n",
    "    X: DataFrame containing the explanatory variables\n",
    "    \n",
    "    y: Target variable\n",
    "    \n",
    "    reg_dict: Dictionary of trained/fitted models\n",
    "    '''\n",
    "    \n",
    "    test1_scores = []\n",
    "    test2_scores = []\n",
    "    \n",
    "    df_pred = pd.DataFrame(columns=reg_dict.keys()) # Columns of DF will accord with reg_dict keys\n",
    "    \n",
    "    # Loop through Dictionary items\n",
    "    for key, reg in reg_dict.items():\n",
    "        \n",
    "        pred_y = reg.predict(X)\n",
    "        df_pred[key] = pd.Series(pred_y).transpose()\n",
    "        \n",
    "        # Computing test scores for each model\n",
    "        test1_scores.append(round(mean_absolute_error(y, pred_y), 4))\n",
    "        test2_scores.append(round(mean_squared_error(y, pred_y, squared=False), 4))\n",
    "        \n",
    "    # Generate results DataFrame\n",
    "    results = pd.DataFrame({'Model': list(reg_dict.keys()), \n",
    "                            'Mean Absolute Error': test1_scores,\n",
    "                            'Root Mean Squared Error': test2_scores\n",
    "                            })\n",
    "    \n",
    "    # Add target variable to the DataFrame of predictions\n",
    "    df_pred['Target'] = y.tolist()\n",
    "    \n",
    "    return results, df_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ea16c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of TRAINED models\n",
    "reg_dict = {\n",
    "    'Lasso Regression': rs_las,\n",
    "    'Ridge Regression': rs_rdg,\n",
    "    'Random Forest': rs_rf,\n",
    "    'Xtreme Gradient Boost': rs_xgb,\n",
    "    'Support Vector Machine': rs_svm,\n",
    "    'Multi-Layer Perceptron': rs_mlp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "700c41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cyc, df_pred_cyc = reg_scoring(X_cyct, y_cyct, reg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb4188ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_cyc['date'] = df_cyct.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1808a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pred_cyc.to_csv(r'C:\\\\ny_pred_cyc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf5085",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f28fb10",
   "metadata": {},
   "source": [
    "### Cross-validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9979a10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Average MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>396.0423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>396.4415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>137.3749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xtreme Gradient Boost</td>\n",
       "      <td>120.9380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>1073.7258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multi-Layer Perceptron</td>\n",
       "      <td>255.7837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Average MAE\n",
       "0        Lasso Regression     396.0423\n",
       "1        Ridge Regression     396.4415\n",
       "2           Random Forest     137.3749\n",
       "3   Xtreme Gradient Boost     120.9380\n",
       "4  Support Vector Machine    1073.7258\n",
       "5  Multi-Layer Perceptron     255.7837"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_cyc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0b46fd",
   "metadata": {},
   "source": [
    "### Test data scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "828ef354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>382.1898</td>\n",
       "      <td>480.1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>382.3853</td>\n",
       "      <td>480.4957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>131.4494</td>\n",
       "      <td>175.9876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xtreme Gradient Boost</td>\n",
       "      <td>116.8413</td>\n",
       "      <td>156.4439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>323.2023</td>\n",
       "      <td>423.3375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multi-Layer Perceptron</td>\n",
       "      <td>382.1247</td>\n",
       "      <td>480.4495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Mean Absolute Error  Root Mean Squared Error\n",
       "0        Lasso Regression             382.1898                 480.1887\n",
       "1        Ridge Regression             382.3853                 480.4957\n",
       "2           Random Forest             131.4494                 175.9876\n",
       "3   Xtreme Gradient Boost             116.8413                 156.4439\n",
       "4  Support Vector Machine             323.2023                 423.3375\n",
       "5  Multi-Layer Perceptron             382.1247                 480.4495"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_cyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e873c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
